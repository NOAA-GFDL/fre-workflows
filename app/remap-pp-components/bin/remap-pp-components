#!/usr/bin/env python
"""
Description: Remap/move components that will be
             post-processed from one convention,
             such as history files, to an
             updated output directory structure
"""
import os
import subprocess
import glob
from pathlib import Path
import metomi.rose.config as mrc
import ast
import yaml
from pathlib import Path
import json
import ast 

import logging
logging.basicConfig()
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

def verify_dirs(in_dir,out_dir):
    """
    Verify that the input and output directories exists and are directories
    Params:
        output_dir: output directory
        input_dir: input directory
    """

    # Verify input directory exists and is a directory
    if Path(in_dir).is_dir():
        print("Input directory is a valid directory")
    else:
        raise Exception(f"Error: Input directory {in_dir} is not a valid directory")

    # Verify output directory exists and is a directory
    if Path(out_dir).is_dir():
        print("Output directory is a valid directory")
    else:
        raise Exception(f"Error: Output directory {out_dir} is not a valid directory")

def create_dir(out_dir,comp,freq,chunk,ens,dir_ts):
    """
    Create the output directory structure
    Params:
        out_dir: output directory
        comp: component that will be post-processed
        freq: frequency
        chunk: chunk
        ens: ensemble member
        dir_ts: directory time series workaround
    """

    # Define dir
    if ens is not None:
        if dir_ts:
            dirs = f"{comp}/ts/{ens}/{freq}/{chunk}"
        else:
            dirs = f"{comp}/{ens}/{freq}/{chunk}"
    else:
        if dir_ts:
            dirs = f"{comp}/ts/{freq}/{chunk}"
        else:
            dirs = f"{comp}/{freq}/{chunk}"

    # Create dir from outputDir
    os.chdir(out_dir)
    Path(dirs).mkdir(parents=True,exist_ok=True)

    return dirs

def freq_to_legacy(iso_dura):
    """
    Print Bronx-style frequency given an ISO8601 duration
    Params:
        iso_dura: frequency
    """

    if iso_dura=='P1Y':
        freq_legacy = 'annual'
    elif iso_dura=='P1M':
        freq_legacy = 'monthly'
    elif iso_dura=='P3M':
        freq_legacy = 'seasonal'
    elif iso_dura=='P1D':
        freq_legacy = 'daily'
    elif iso_dura=='PT120H':
        freq_legacy = '120hr'
    elif iso_dura=='PT12H':
        freq_legacy = '12hr'
    elif iso_dura=='PT8H':
        freq_legacy = '8hr'
    elif iso_dura=='PT6H':
        freq_legacy = '6hr'
    elif iso_dura=='PT4H':
        freq_legacy = '4hr'
    elif iso_dura=='PT3H':
        freq_legacy = '3hr'
    elif iso_dura=='PT2H':
        freq_legacy = '2hr'
    elif iso_dura=='PT1H':
        freq_legacy = 'hourly'
    elif iso_dura=='PT30M':
        freq_legacy = '30min'
    else:
        raise ValueError("Could not convert ISO duration '{iso_dura}'")

    return freq_legacy

def chunk_to_legacy(iso_dura):
    """
    Print Bronx-style frequency given an ISO8601 duration
    Params:
        iso_dura: chunk
    """

    if iso_dura[0]=='P':
        if iso_dura[-1:]=='M':
            brx_freq=iso_dura[1]+'mo'
        elif iso_dura[-1:]=='Y':
            brx_freq=iso_dura[1]+'yr'
        else:
            brx_freq = 'error'
    else:
        brx_freq = 'error'

    return brx_freq

def freq_to_date_format(iso_freq):
    """
    Print legacy Bronx-like date template format given a frequency (ISO 8601 duration)
    Params:
        iso_freq: frequency
    """

    if iso_freq=='P1Y':
        return 'CCYY'
    elif iso_freq=='P1M':
        return 'CCYYMM'
    elif iso_freq=='P1D':
        return 'CCYYMMDD'
    elif (iso_freq[:2]=='PT') and (iso_freq[-1:]=='H'):
        return 'CCYYMMDDThh'
    else:
        return f'ERROR: Unknown Frequency {iso_freq}'

def truncate_date(date, freq):
    """
    Print a date string to a truncated precision.
        - Accepts a date and frequency
        - Outputs a date string with suitably reduced precision
        - Test cases: '19790101T0000Z P1D', '19800101T0000Z P1M', '19790101T0000Z PT0.5H'
        - Output using cylc (shared.sh calls in job logs): '19790101', '198001', '1979010100'
    Params:
        date: date to begin post-processing
        freq: frequency
    """

    form = freq_to_date_format(freq)
    print(f"truncatedateformat: {form}")
    output = subprocess.Popen(["cylc", "cycle-point", "--template", form, date],
                              stdout=subprocess.PIPE)

    bytedate = output.communicate()[0]
    date=str(bytedate.decode())
    print(f"truncatedate: {date}")

    #remove trailing newline
    date=date[:(len(date)-1)]

    #check for and remove 'T' if present
    if not date.isnumeric():
        date=date[:8]+date[-2:]

    return date

def search_files(product,var,source,freq,current_chunk,begin):
    """
    Pattern match and search for the correct files in the chunk directory
    Params:
        var: variables
        source: source history files for post-processed component
        begin: date to begin post-processing
        current_chunk: current chunk to post-process
        freq: frequency
    """

    # with glob - files seen as list
    if freq == "P0Y":
        if var == "all":
            files = glob.glob(f"{source}.*.nc")
        else:
            for v in var:
                files = glob.glob(f"{source}.{v}*.nc")
    else:
        if product == "ts":
            date = truncate_date(begin, freq)
            print(f"date: {date}")
        elif product == "av":
            date = truncate_date(begin, "P1Y")
        else:
            raise Exception("Product not set to ts or av.")

        if var == "all":
            files = glob.glob(f"{source}.{date}-*.*.nc")
        else:
            for v in var:
                print(f"var: {v}")
                files = glob.glob(f"{source}.{date}-*.{v}*.nc")

        if product == "av" and current_chunk == "P1Y":
            files = glob.glob(f"{source}.{date}.*.nc")

    return files

def get_variables(comp_info, product):
    """
    Retrieve variables listed for a component
    Params:
        comp_info: information about requested component
        product: static, ts, or av
    """
    if product == "static":
        if comp_info.get("static") is not None:
            for static_info in comp_info.get("static"):
                if static_info.get("variables") is not None:
                    v = static_info.get("variables")
                else:
                    v = "all"
        else:
            raise ValueError(f"Product is set to static but no static sources/variables defined for {comp_info.get('type')}")
#        if comp_info.get("static") is not None:
#            for static_info in comp_info.get("static"):
#                if static_info.get("variables") is not None:
#                    v = static_info.get("variables")
#                else:
#                    v = "all"
#        else:
#            raise ValueError(f"Product is set to static but no static sources/variables defined for {comp_info.get('type')}")
    else:
        for src_info in comp_info.get("sources"): #history_file,variables
            if src_info.get("variables"):
                v = src_info.get("variables")
            else:
                v = "all"

    return v

def get_sources(comp_info, product):
    """
    Retrieve source name for a component
    Params:
        comp_info: information about requested component
        product: static, ts, or av
    """
    sources = []
    if "static" in product:
        for static_info in comp_info.get("static"):
            if static_info.get("source") is not None:
                sources.append(static_info.get("source"))
#            if static_info.get("offline_source") is not None:
#                offline_src_filename = static_info.get("offline_source").split("/")[-1]
#                offline_src_name = os.path.splitext(offline_src_filename)
#                sources.append(offline_src_name[0])
    else:
        for src_info in comp_info.get("sources"):
            sources.append(src_info.get("history_file"))

    return sources

def get_freq(comp_info, product):
    if "freq" not in comp_info.keys():
        freq = glob.glob("*")
    else:
        freq = comp_info.get("freq")

    return freq

def get_chunk(comp_info, product):
    if "chunk" not in comp_info.keys():
        chunk = glob.glob("*")
    else:
        chunk = comp_info.get("chunk")

    return chunk
##################################### MAIN FUNCTION #####################################
def remap():
    """
    Remap history files to an updated output directory structure
    Params:
        input_dir: input directory
        output_dir: output directory
        begin: date to begin post-processing
        current_chunk: current chunk to post-process
        components: components that will be post-processed
        product: variable to define time series or time averaging
        dir_ts_workaround: time series workaround
        ens_mem: ensemble member number
    """

    # Set variables
    input_dir         = os.getenv('inputDir')
    output_dir        = os.getenv('outputDir')
    begin             = os.getenv('begin')
    current_chunk     = os.getenv('currentChunk')
    components        = os.getenv('components')
    yaml_config       = os.getenv('yaml_config')
    product           = os.getenv('product')
    dir_ts_workaround = os.getenv('dirTSWorkaround')
    ens_mem           = os.getenv('ens_mem')
    osd               = os.getenv("offline_src_dict")
    # convert string to dictionary
    offline_src_dict = ast.literal_eval(osd)

    print("Arguments:")
    print("    input dir: "+input_dir)
    print("    output dir: "+output_dir)
    print("    begin: "+begin)
    print("    current chunk: "+current_chunk)
    print("    components: "+components)
    print("    yaml config: "+yaml_config)
    print("    product: "+product)
    print("    offline diagnostics: "+osd)
    if dir_ts_workaround is not None:
        print("    dirTSWorkaround: "+dir_ts_workaround)
    else:
        print("    dirTSWorkaround: None")
    if ens_mem is not None:
        print("    ens_mem: "+ens_mem)
    else:
        print("    ens_mem: None")
    copy_tool = os.getenv('COPY_TOOL')

    # Path to yaml configuration
    exp_dir = Path(__file__).resolve().parents[3]
    path_to_yamlconfig = os.path.join(exp_dir, yaml_config)
    # Load and read yaml configuration 
    with open(path_to_yamlconfig,'r') as yml:
        yml_info = yaml.safe_load(yml)

    # Verify the input and output directories
    verify_dirs(input_dir, output_dir)

    # Start in input directory)
    os.chdir(input_dir)

    # loop through components to be post processed
    # list of components
    comps = components.split()
    for comp in comps:
        comp = comp.strip('""')

        # Make sure component/source is in the yaml configuration file
        for comp_info in yml_info["postprocess"]["components"]:
            components = comp_info.get("type")

            # Check that pp_components defined matches those in the yaml file
            logger.debug(f"Is {comp} in {components}?")
            if comp in components:
                logger.debug('Yes')
            else:
                logger.warning('f"WARNING: component {comp} does not exist in yaml config')
                continue

            #if static but no static defined, skip
            if product == "static":
                if comp_info.get("static") is None:
                    logger.warning('Product set to "static" but no static source requested defined')
                    continue
 
            ## VARIABLE INFORMATION
            # Save variables if defined
            v = get_variables(comp_info, product)

            ## Loop through grid
            # Set grid type if component has xyInterp defined or not
            grid = []
            if "xyInterp" not in comp_info.keys():
                grid.append("native")
            else:
                interp = comp_info.get("xyInterp").split(",")
                interp = '_'.join(interp)
                interp_method = comp_info.get("interpMethod")
                grid.append(f"regrid-xy/{interp}.{interp_method}")     

            for g in grid:
                if ens_mem is not None:
                    newdir = f"{input_dir}/{g}/{ens_mem}"
                    os.chdir(newdir)
                else:
                    os.chdir(f"{input_dir}/{g}")

                ## Loop through sources
                sources = get_sources(comp_info, product)
                print(f"SOURCES: {sources}")
                for s in sources:
                    if ens_mem is not None:
                        source_dir = os.path.join(input_dir, g, ens_mem, s)
                    else:
                        source_dir = os.path.join(input_dir, g, s)
                    if not os.path.exists(source_dir) and product == "av":
                        print(f"Source directory '{source_dir}' does not exist, but this could be expected, so skipping.")
                        continue
                    os.chdir(source_dir)

                    ## Loop through freq
                    freq = get_freq(comp_info, product) ###might have to be a list
                 
                    for f in freq:
                        if ens_mem is not None:
                            os.chdir(f"{input_dir}/{g}/{ens_mem}/{s}/{f}")
                        else:
                            os.chdir(f"{input_dir}/{g}/{s}/{f}")

                        ## Loop through chunk
                        chunk = get_chunk(comp_info, product)  ## might have to be a list ...
                        for c in chunk:
                            if c != current_chunk:
                                continue
                            if ens_mem is not None:
                                os.chdir(f"{input_dir}/{g}/{ens_mem}/{s}/{f}/{c}")
                            else:
                                os.chdir(f"{input_dir}/{g}/{s}/{f}/{c}")

                            # Create directory
                            # ts output is written to final location, av is not.
                            # so convert the ts only to bronx-style
                            if product == "ts":
                                dirs = create_dir(out_dir = output_dir,
                                                  comp = comp,
                                                  freq = freq_to_legacy(f),
                                                  chunk = chunk_to_legacy(c),
                                                  ens = ens_mem,
                                                  dir_ts = dir_ts_workaround)
                            else:
                                dirs = create_dir(out_dir = output_dir,
                                                  comp = comp,
                                                  freq = f,
                                                  chunk = c,
                                                  ens = ens_mem,
                                                  dir_ts = dir_ts_workaround)

                            print(f"directory created: {dirs}")
##########
                            # Search for files in chunk directory
                            if ens_mem is not None:
                                os.chdir(f"{input_dir}/{g}/{ens_mem}/{s}/{f}/{c}")
                            else:
                                os.chdir(f"{input_dir}/{g}/{s}/{f}/{c}")
                            files = search_files(product = product,
                                                 var = v,
                                                 source = s,
                                                 freq = f,
                                                 current_chunk = current_chunk,
                                                 begin = begin)
                            print(f"{len(files)} files found for component '{comp}', source '{s}', product '{product}', grid '{g}', chunk '{c}': {files}")
##########

                            if not files:
                                if ens_mem is not None:
                                    raise Exception("\nError: No input files found in",
                                                    f"{input_dir}/{g}/{ens_mem}/{s}/{f}/{c}")
                                else:
                                    raise Exception("\nError: No input files found in",
                                                    f"{input_dir}/{g}/{s}/{f}/{c}")

                            os.chdir(output_dir)

                            for file in files:
                                newfile1 = file.split(".",1)[1]
                                newfile2 = f"{comp}.{newfile1}"
                                # If file exists, remove it
                                # (would exist if workflow was run previously)
                                output_file = os.path.join(output_dir, dirs, newfile2)
                                if os.path.exists(output_file):
                                    os.remove(output_file)

                                # Replace with new file
                                if ens_mem is not None:
                                    link = ["ln",
                                            f"{input_dir}/{g}/{ens_mem}/{s}/{f}/{c}/{file}",
                                            f"{output_dir}/{dirs}/{newfile2}"]
                                else:
                                    link = ["ln",
                                            f"{input_dir}/{g}/{s}/{f}/{c}/{file}",
                                            f"{output_dir}/{dirs}/{newfile2}"]

                                run = subprocess.run( link, check = False )
                                ret = run.returncode

                                if ret != 0:
                                    if ens_mem is None:
                                        copy = [f"{copy_tool}",
                                                f"{input_dir}/{g}/{s}/{f}/{c}/{file}",
                                                f"{output_dir}/{dirs}/{newfile2}" ]
                                        subprocess.run( copy, check = False )
                                    else:
                                        copy = [f"{copy_tool}",
                                                f"{input_dir}/{g}/{ens_mem}/{s}/{f}/{c}/{file}",
                                                f"{output_dir}/{dirs}/{newfile2}" ]
                                        subprocess.run( copy, check = False )

                            # Symlink or copy the offline diagnostic file for the
                            # specified component in the output directory.
                            # Offline diagnostic files will then be in the same 
                            # location as other static files to be combined.
                            for key in offline_src_dict.keys():
                                if comp == key:
                                    for off_file in offline_src_dict[key]:
                                        offline_link = ["ln",
                                                        "-s",
                                                        f"{off_file}",
                                                        f"{output_dir}/{dirs}"]
                                        offline_link_run = subprocess.run( offline_link, check = False )
                                        offline_link_ret = offline_link_run.returncode

                                        if offline_link_ret != 0:
                                            #raise ValueError("copy failed")
                                            offline_copy = ["{copy_tool}",
                                                            f"{off_file}",
                                                            f"{output_dir}/{dirs}"]
                                            subprocess.run( offline_copy, check = False )
                                else:
                                    logger.info(f"No offline diagnostic files associated with {comp}.")

    print("Component remapping complete")

if __name__ == '__main__':
    remap() 
